{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_wave_mask_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaWRg8cNukJFrOEk8RB71E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvanhemert/DeepLearning/blob/main/deep_wave_mask_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsm6jCoXJSum",
        "outputId": "001a2dde-df6b-4efe-ee58-248a221e06a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a51f7778"
      },
      "source": [
        "# builtins\n",
        "import locale\n",
        "import math\n",
        "import glob\n",
        "import pathlib\n",
        "import functools\n",
        "import logging\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# numerical stuff\n",
        "#import pickle5 as pickle\n",
        "import tables\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "#from tensorflow.python import ipu\n",
        "\n",
        "#import libpvti as pvti\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmKbYE3o1TQL",
        "outputId": "2824c5f9-deaa-42e9-b3e3-ffc154715e7d"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.56.148.10:8470']\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.56.148.10:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.56.148.10:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ed43b62"
      },
      "source": [
        "data_path_train = 'gs://bathy_sample/processed/20211013/train_data_no_schematic'\n",
        "data_path_test = 'gs://bathy_sample/processed/20211013/test_data_no_schematic'\n",
        "#meta_data_path = '/mnt/poddata/data/bathy-emodnet-a-runs.h5'\n",
        "#all_checkpoints_path = 'gs://bathy_sample/dnn/checkpoints'\n",
        "all_checkpoints_path = '/content/drive/MyDrive/DeepLearning/Benchmark/checkpoints'\n",
        "model_name = 'guus-2d-mlp-cnn-v0.9'\n",
        "model_path = '/content/drive/MyDrive/DeepLearning/Benchmark/models'\n",
        "checkpoints_path = all_checkpoints_path + '/' + model_name\n",
        "\n",
        "learning_rate = 1e-4\n",
        "n_epochs = 100\n",
        "batch_size = 8 * tpu_strategy.num_replicas_in_sync\n",
        "steps_per_execution = 1\n",
        "steps_per_epoch = 112\n",
        "validation_steps = 320\n",
        "gradient_accumulation_steps_per_replica = 8\n",
        "raster_shape = (256, 256, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eaa8178"
      },
      "source": [
        "def tf_parse(eg):\n",
        "    \"\"\"parse an example (or batch of examples, not quite sure...)\"\"\"\n",
        "\n",
        "    # here we re-specify our format\n",
        "    # you can also infer the format from the data using tf.train.Example.FromString\n",
        "    # but that did not work\n",
        "    example = tf.io.parse_example(\n",
        "        eg[tf.newaxis],\n",
        "        {\n",
        "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'bathy': tf.io.FixedLenFeature([], tf.string),\n",
        "            'hs': tf.io.FixedLenFeature([], tf.string),\n",
        "            'tm01': tf.io.FixedLenFeature([], tf.string),\n",
        "            'theta0x': tf.io.FixedLenFeature([], tf.string),\n",
        "            'theta0y': tf.io.FixedLenFeature([], tf.string),\n",
        "            'eta': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'zeta': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'theta_wavex': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'theta_wavey': tf.io.FixedLenFeature([], tf.float32),\n",
        "            #'mask': tf.io.FixedLenFeature([], tf.string),\n",
        "        },\n",
        "    )\n",
        "    bathy = tf.io.parse_tensor(example[\"bathy\"][0], out_type=\"float32\")\n",
        "    bathy = tf.ensure_shape(bathy, raster_shape)    # ensure shape, to be able to train the model\n",
        "    hs = tf.io.parse_tensor(example[\"hs\"][0], out_type=\"float32\")\n",
        "    hs = tf.ensure_shape(hs, raster_shape)\n",
        "    tm01 = tf.io.parse_tensor(example[\"tm01\"][0], out_type=\"float32\")\n",
        "    theta0x = tf.io.parse_tensor(example[\"theta0x\"][0], out_type=\"float32\")\n",
        "    theta0y = tf.io.parse_tensor(example[\"theta0y\"][0], out_type=\"float32\")\n",
        "    eta = example[\"eta\"]\n",
        "    zeta = example[\"zeta\"]\n",
        "    theta_wavex = example[\"theta_wavex\"]\n",
        "    theta_wavey = example[\"theta_wavey\"]\n",
        "    #mask = tf.io.parse_tensor(example[\"mask\"][0], out_type=\"bool\")\n",
        "    #mask = tf.cast(mask, dtype=\"float32\")\n",
        "    #mask = tf.ensure_shape(mask, raster_shape)\n",
        "    #img_input = tf.concat([bathy,mask],-1)\n",
        "    attr = tf.stack([eta, zeta, theta_wavex, theta_wavey], axis=1)\n",
        "    attr = tf.reshape(attr,shape=[-1])\n",
        "    output = (hs, tm01, theta0x, theta0y)\n",
        "    output = hs\n",
        "    return (bathy, attr), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f602af"
      },
      "source": [
        "def get_files(data_path):\n",
        "    files = tf.io.gfile.glob(data_path + \"/\" + \"*.tfrecords\")\n",
        "    return files\n",
        "\n",
        "def get_dataset(files):\n",
        "    \"\"\"return a tfrecord dataset with all tfrecord files\"\"\"\n",
        "    dataset =  tf.data.TFRecordDataset(files)\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9OjbHWFSu4s"
      },
      "source": [
        "def AttnBlock2D(x, g, inter_channel):\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
        "\n",
        "    f = Activation('relu')(tf.keras.layers.add([theta_x, phi_g]))\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    att_x = tf.keras.layers.multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer):\n",
        "    \n",
        "    in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    up = UpSampling2D(size=(2, 2))(down_layer)\n",
        "    layer = AttnBlock2D(x=layer, g=up, inter_channel=in_channel // 4)\n",
        "    \n",
        "    my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "    \n",
        "    concate = my_concat([up, layer])\n",
        "    return concate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47f5c590"
      },
      "source": [
        "def full_model(cnn_input_shape, mlp_input_shape):#, mask_input_shape):\n",
        "    \n",
        "    mlp_input = Input(mlp_input_shape)\n",
        "    cnn_input = Input(cnn_input_shape)\n",
        "    #mask_input = Input(mask_input_shape)\n",
        "    x = Dense(256, activation='relu')(mlp_input)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    mlp_output = Dense(4, activation='relu')(x)\n",
        "\n",
        "    x = Conv2D(16, (3,3), padding=\"same\")(cnn_input)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x1)\n",
        "\n",
        "    x = Conv2D(32, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x2 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x2)\n",
        "\n",
        "    x = Conv2D(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x3 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x3)\n",
        "\n",
        "    x = Conv2D(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x4 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x4)\n",
        "    \n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    cnn_output = BatchNormalization()(x)\n",
        "\n",
        "    conv_shape = K.int_shape(cnn_output)\n",
        "\n",
        "    x = Flatten()(cnn_output)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(16, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(4, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Concatenate()([x,mlp_output])\n",
        "    x = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Reshape((conv_shape[1],conv_shape[2],int(conv_shape[3])))(x)\n",
        "\n",
        "    #Concatenate cnn_output before compression with MLP output\n",
        "    x = tf.keras.layers.add([x, cnn_output])\n",
        "\n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = attention_up_and_concate(x, x4)\n",
        "    x = Conv2DTranspose(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = attention_up_and_concate(x, x3)\n",
        "    x = Conv2DTranspose(32, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = attention_up_and_concate(x, x2)\n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = attention_up_and_concate(x, x1)\n",
        "\n",
        "    x = Conv2DTranspose(1, (3,3), padding=\"same\", activation=\"linear\")(x)\n",
        "\n",
        "    model = Model(inputs=[cnn_input, mlp_input], outputs = x)\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c585d94"
      },
      "source": [
        "train_files = get_files(data_path_train)\n",
        "test_files = get_files(data_path_test)\n",
        "\n",
        "train_dataset = get_dataset(train_files)\n",
        "test_dataset = get_dataset(test_files)\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5701e49"
      },
      "source": [
        "#for sample in train_dataset.take(1):\n",
        " #   print(repr(sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a01a94a",
        "outputId": "faee5869-8583-4ca3-b593-0aab67b35955"
      },
      "source": [
        "start = time.time()\n",
        "print(time.ctime(start))\n",
        "with tpu_strategy.scope():\n",
        "    model = full_model((256, 256, 1), 4)\n",
        "    opt = Adam(learning_rate=learning_rate, decay=learning_rate / n_epochs)\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=opt, steps_per_execution=steps_per_execution)\n",
        "    \n",
        "    callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoints_path, \n",
        "        save_weights_only=True,\n",
        "        #monitor='val_mse',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    tf.keras.callbacks.CSVLogger(\n",
        "        filename=checkpoints_path + '.csv')\n",
        "    ]\n",
        "    \n",
        "    model.fit(x=train_dataset, validation_data=test_dataset, epochs=n_epochs, callbacks=callbacks)#, steps_per_epoch=steps_per_epoch)\n",
        "    #model.save(model_path + '/' + model_name + '.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(time.ctime(end))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 14 13:52:03 2021\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 555s 5s/step - loss: 54.5057 - val_loss: 58.6131\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 54s 479ms/step - loss: 43.0227 - val_loss: 51.8219\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 54s 480ms/step - loss: 39.5843 - val_loss: 42.6138\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 34.6005 - val_loss: 36.5374\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 28.1859 - val_loss: 28.9242\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 21.3298 - val_loss: 20.3402\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 15.2974 - val_loss: 12.4337\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 10.9068 - val_loss: 10.0411\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 55s 492ms/step - loss: 8.0409 - val_loss: 10.3568\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 54s 481ms/step - loss: 6.3360 - val_loss: 10.6774\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 55s 491ms/step - loss: 5.4086 - val_loss: 9.3015\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 4.8590 - val_loss: 8.2916\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 55s 492ms/step - loss: 4.5460 - val_loss: 7.0894\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 55s 488ms/step - loss: 4.3106 - val_loss: 5.8452\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 4.0899 - val_loss: 5.0852\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 3.8438 - val_loss: 3.8505\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 3.6455 - val_loss: 3.5032\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 55s 485ms/step - loss: 3.5140 - val_loss: 3.1532\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 56s 495ms/step - loss: 3.3165 - val_loss: 4.3363\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 3.0525 - val_loss: 3.1073\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 2.8085 - val_loss: 2.9618\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 2.7045 - val_loss: 2.9394\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 2.6644 - val_loss: 3.4002\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 2.6021 - val_loss: 2.9903\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 2.3790 - val_loss: 3.6273\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 54s 479ms/step - loss: 2.2259 - val_loss: 4.0590\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 55s 491ms/step - loss: 2.1654 - val_loss: 6.2309\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 2.0599 - val_loss: 6.8963\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 1.9818 - val_loss: 5.7392\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.8971 - val_loss: 6.5390\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 1.8553 - val_loss: 3.8071\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.7883 - val_loss: 4.3103\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 1.7513 - val_loss: 2.9401\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 55s 488ms/step - loss: 1.6954 - val_loss: 4.6320\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 55s 493ms/step - loss: 1.6905 - val_loss: 9.0804\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 1.6951 - val_loss: 6.7677\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.6671 - val_loss: 7.0774\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 1.6164 - val_loss: 6.6071\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 1.5780 - val_loss: 5.5500\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 1.5578 - val_loss: 5.5987\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 1.5040 - val_loss: 5.7805\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 1.4200 - val_loss: 4.5114\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 1.4003 - val_loss: 5.2955\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 1.4008 - val_loss: 4.7335\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 1.4187 - val_loss: 5.4769\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 54s 480ms/step - loss: 1.3712 - val_loss: 5.1322\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 1.3140 - val_loss: 5.7499\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 1.2534 - val_loss: 5.5485\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.2222 - val_loss: 4.9205\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 1.2133 - val_loss: 5.8127\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 55s 488ms/step - loss: 1.1955 - val_loss: 5.1294\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 56s 495ms/step - loss: 1.2005 - val_loss: 4.6051\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.1552 - val_loss: 5.4537\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.1351 - val_loss: 4.9857\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 1.1527 - val_loss: 5.1525\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 54s 478ms/step - loss: 1.1569 - val_loss: 4.9980\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 54s 477ms/step - loss: 1.1958 - val_loss: 4.7760\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 1.1831 - val_loss: 3.8638\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 1.1403 - val_loss: 3.6594\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 55s 491ms/step - loss: 1.0994 - val_loss: 3.5546\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 1.0472 - val_loss: 3.4917\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 1.0023 - val_loss: 3.8728\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 0.9990 - val_loss: 3.7717\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 54s 480ms/step - loss: 0.9791 - val_loss: 4.5349\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 0.9881 - val_loss: 3.9059\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 54s 481ms/step - loss: 0.9812 - val_loss: 3.8968\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 53s 474ms/step - loss: 0.9711 - val_loss: 4.6918\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 0.9733 - val_loss: 4.1639\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 54s 485ms/step - loss: 0.9814 - val_loss: 4.3268\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 0.9761 - val_loss: 3.4379\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 53s 476ms/step - loss: 0.9613 - val_loss: 3.8232\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 0.9374 - val_loss: 3.4229\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 0.9365 - val_loss: 3.1814\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 54s 478ms/step - loss: 0.9158 - val_loss: 3.3902\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 54s 483ms/step - loss: 0.8933 - val_loss: 3.8019\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 0.8683 - val_loss: 3.7881\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 54s 479ms/step - loss: 0.8784 - val_loss: 3.3019\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 0.9012 - val_loss: 3.6185\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 0.8929 - val_loss: 3.8907\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 0.9122 - val_loss: 3.1375\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 0.9348 - val_loss: 3.8133\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 54s 479ms/step - loss: 0.9126 - val_loss: 3.8340\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 55s 488ms/step - loss: 0.8867 - val_loss: 3.5021\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 55s 486ms/step - loss: 0.8683 - val_loss: 3.1205\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 54s 476ms/step - loss: 0.8442 - val_loss: 3.0952\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 0.8194 - val_loss: 3.1275\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 53s 473ms/step - loss: 0.8063 - val_loss: 3.6192\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 0.8285 - val_loss: 3.1366\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 53s 473ms/step - loss: 0.7387 - val_loss: 3.2689\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 53s 475ms/step - loss: 0.7056 - val_loss: 3.3837\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 0.7031 - val_loss: 2.9073\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 55s 492ms/step - loss: 0.7030 - val_loss: 2.9245\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 54s 477ms/step - loss: 0.7104 - val_loss: 2.8373\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 54s 479ms/step - loss: 0.7160 - val_loss: 3.6065\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 0.7577 - val_loss: 3.3574\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 0.7805 - val_loss: 3.3066\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 0.7893 - val_loss: 3.2930\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 54s 482ms/step - loss: 0.7314 - val_loss: 3.0376\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 54s 484ms/step - loss: 0.7042 - val_loss: 3.5012\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 54s 481ms/step - loss: 0.6921 - val_loss: 3.2868\n",
            "Sun Nov 14 15:32:22 2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d45a71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d2f92b-b34e-4d2d-cac3-ce5b318790b3"
      },
      "source": [
        "print(start, end)\n",
        "print(\"Starting time: \", time.ctime(start))\n",
        "print(\"Ending time: \", time.ctime(end))\n",
        "print(\"Time elapsed: \", datetime.timedelta(seconds=round(end - start)))\n",
        "print('')\n",
        "print(\"Number of parameters: \", model.count_params())\n",
        "print(\"\")\n",
        "model.save(model_path + '/' + model_name + '.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1636718988.9702184 1636725072.4822314\n",
            "Starting time:  Fri Nov 12 12:09:48 2021\n",
            "Ending time:  Fri Nov 12 13:51:12 2021\n",
            "Time elapsed:  1:41:24\n",
            "\n",
            "Number of parameters:  7396993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "816f856c"
      },
      "source": [
        "logging.info(\"training model...\")\n",
        "# TODO properly compute steps for progress bar (low priority)\n",
        "steps_per_epoch = len(train_files) * 10 // batch_size\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoints_path, \n",
        "        save_weights_only=True,\n",
        "        monitor='val_mse',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "model.fit(x=train_dataset, validation_data=test_dataset, epochs=n_epochs, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83c5e4dc",
        "outputId": "97f2f447-606f-4942-ee3e-32da628d6db6"
      },
      "source": [
        "model.summary()\n",
        "model.count_params()\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 16) 160         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 16) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 16) 64          activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 65536)        0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           4194368     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          1280        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64)           256         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 16)           1040        batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16)           64          dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4)            68          batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           528         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4)            16          dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            68          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           batch_normalization_8[0][0]      \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 65536)        589824      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 65536)        262144      dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 256)  0           reshape[0][0]                    \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 256)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 16, 16, 256)  590080      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  590080      up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  295040      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 73792       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 32) 18464       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 128, 128, 32) 0           conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 128, 128, 16) 4624        batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 128, 128, 16) 0           conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 16) 64          activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 16) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 256, 256, 1)  145         up_sampling2d_3[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 8,244,633\n",
            "Trainable params: 8,109,873\n",
            "Non-trainable params: 134,760\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8244633"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0e59b97",
        "outputId": "354fc59a-d531-40de-e83b-409ea2d2307b"
      },
      "source": [
        "pd.read_hdf(meta_data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>$\\zeta$</th>\n",
              "      <th>$\\theta_{wave}$</th>\n",
              "      <th>$\\eta$</th>\n",
              "      <th>$bathy_i$</th>\n",
              "      <th>bathy_file</th>\n",
              "      <th>bathy</th>\n",
              "      <th>uuid</th>\n",
              "      <th>run_id</th>\n",
              "      <th>bathy_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>88c98d1f-6307-43b5-a8bd-0cc6b23e105e</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>462</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-13.052446, -12.792448, -12.792448, -12.5124...</td>\n",
              "      <td>b38a89ab-f021-42dc-808e-e116dd924a46</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>318908b3-1ed1-4117-8226-6eaeb2846a24</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>462</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-13.052446, -12.792448, -12.792448, -12.5124...</td>\n",
              "      <td>dee4ae77-a3af-4e73-9f16-54b7ac589158</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.283185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>e7bb6f7b-69db-4515-9dcf-6dc009d4d775</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>13.282544</td>\n",
              "      <td>3.631269</td>\n",
              "      <td>8.666409</td>\n",
              "      <td>100</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-21.735966, -21.735966, -21.635967, -21.6359...</td>\n",
              "      <td>65382ebd-1b80-4d75-9287-8bb7f2a41db0</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>13.581516</td>\n",
              "      <td>2.358778</td>\n",
              "      <td>29.419263</td>\n",
              "      <td>402</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[6.6918297, 6.6918297, 6.6918297, 6.6918297, ...</td>\n",
              "      <td>0402bcb5-7309-4662-8a18-93f1dccde9b4</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>8.416452</td>\n",
              "      <td>5.184157</td>\n",
              "      <td>14.352605</td>\n",
              "      <td>151</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.3258033, -1.3258033, -1.3258033, -1.32580...</td>\n",
              "      <td>065553d1-f60d-4d7e-997e-0b07747682be</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>1.511433</td>\n",
              "      <td>5.741217</td>\n",
              "      <td>39.150158</td>\n",
              "      <td>367</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[20.617117, 20.617117, 20.017117, 20.017117, ...</td>\n",
              "      <td>06577167-1089-49f4-aea7-2f736f9398ca</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>11.297443</td>\n",
              "      <td>6.277600</td>\n",
              "      <td>5.148588</td>\n",
              "      <td>452</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[18.348408, 18.348408, 17.188408, 15.788408, ...</td>\n",
              "      <td>69686c04-6342-4e3b-9807-80390d75e21e</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1016 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        $\\zeta$  $\\theta_{wave}$     $\\eta$  $bathy_i$  \\\n",
              "0      1.000000         0.000000   1.000000          0   \n",
              "1      1.000000         0.000000   1.000000        462   \n",
              "2      1.000000         0.000000  50.000000          0   \n",
              "3      1.000000         0.000000  50.000000        462   \n",
              "4      1.000000         6.283185   1.000000          0   \n",
              "...         ...              ...        ...        ...   \n",
              "1011  13.282544         3.631269   8.666409        100   \n",
              "1012  13.581516         2.358778  29.419263        402   \n",
              "1013   8.416452         5.184157  14.352605        151   \n",
              "1014   1.511433         5.741217  39.150158        367   \n",
              "1015  11.297443         6.277600   5.148588        452   \n",
              "\n",
              "                                             bathy_file  \\\n",
              "0     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "2     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "3     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "4     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "...                                                 ...   \n",
              "1011  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1012  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1013  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1014  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1015  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "\n",
              "                                                  bathy  \\\n",
              "0     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "1     [[-13.052446, -12.792448, -12.792448, -12.5124...   \n",
              "2     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "3     [[-13.052446, -12.792448, -12.792448, -12.5124...   \n",
              "4     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "...                                                 ...   \n",
              "1011  [[-21.735966, -21.735966, -21.635967, -21.6359...   \n",
              "1012  [[6.6918297, 6.6918297, 6.6918297, 6.6918297, ...   \n",
              "1013  [[-1.3258033, -1.3258033, -1.3258033, -1.32580...   \n",
              "1014  [[20.617117, 20.617117, 20.017117, 20.017117, ...   \n",
              "1015  [[18.348408, 18.348408, 17.188408, 15.788408, ...   \n",
              "\n",
              "                                      uuid run_id bathy_source  \n",
              "0     88c98d1f-6307-43b5-a8bd-0cc6b23e105e      a      emodnet  \n",
              "1     b38a89ab-f021-42dc-808e-e116dd924a46      a      emodnet  \n",
              "2     318908b3-1ed1-4117-8226-6eaeb2846a24      a      emodnet  \n",
              "3     dee4ae77-a3af-4e73-9f16-54b7ac589158      a      emodnet  \n",
              "4     e7bb6f7b-69db-4515-9dcf-6dc009d4d775      a      emodnet  \n",
              "...                                    ...    ...          ...  \n",
              "1011  65382ebd-1b80-4d75-9287-8bb7f2a41db0      a      emodnet  \n",
              "1012  0402bcb5-7309-4662-8a18-93f1dccde9b4      a      emodnet  \n",
              "1013  065553d1-f60d-4d7e-997e-0b07747682be      a      emodnet  \n",
              "1014  06577167-1089-49f4-aea7-2f736f9398ca      a      emodnet  \n",
              "1015  69686c04-6342-4e3b-9807-80390d75e21e      a      emodnet  \n",
              "\n",
              "[1016 rows x 9 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}