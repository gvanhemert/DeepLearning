{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "deep_wave_mask_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMihjJcz/XxaRtjshp5rhyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvanhemert/DeepLearning/blob/MultiInputUpdate/deep_wave_mask_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsm6jCoXJSum",
        "outputId": "450500cc-5c8a-4732-d46b-331fbb4fbc15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a51f7778"
      },
      "source": [
        "# builtins\n",
        "import locale\n",
        "import math\n",
        "import glob\n",
        "import pathlib\n",
        "import functools\n",
        "import logging\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# numerical stuff\n",
        "#import pickle5 as pickle\n",
        "import tables\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "#from tensorflow.python import ipu\n",
        "\n",
        "#import libpvti as pvti\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmKbYE3o1TQL",
        "outputId": "c647230a-fdae-4d21-f71a-717858de2a22"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.94.32.114:8470']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.94.32.114:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.94.32.114:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ed43b62"
      },
      "source": [
        "data_path_train = 'gs://bathy_sample/processed/20211013/train_data_mask_no_schematic'\n",
        "data_path_test = 'gs://bathy_sample/processed/20211013/test_data_mask_no_schematic'\n",
        "#meta_data_path = '/mnt/poddata/data/bathy-emodnet-a-runs.h5'\n",
        "#all_checkpoints_path = 'gs://bathy_sample/dnn/checkpoints'\n",
        "all_checkpoints_path = '/content/drive/MyDrive/DeepLearning/Benchmark/checkpoints'\n",
        "model_name = 'guus-2d-mlp-cnn-v1.0'\n",
        "model_path = '/content/drive/MyDrive/DeepLearning/Benchmark/test_models'\n",
        "checkpoints_path = all_checkpoints_path + '/' + model_name\n",
        "\n",
        "learning_rate = 1e-3\n",
        "n_epochs = 100\n",
        "batch_size = 8 * tpu_strategy.num_replicas_in_sync\n",
        "steps_per_execution = 1\n",
        "steps_per_epoch = 112\n",
        "validation_steps = 320\n",
        "gradient_accumulation_steps_per_replica = 8\n",
        "raster_shape = (256, 256, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eaa8178"
      },
      "source": [
        "def tf_parse(eg):\n",
        "    \"\"\"parse an example (or batch of examples, not quite sure...)\"\"\"\n",
        "\n",
        "    # here we re-specify our format\n",
        "    # you can also infer the format from the data using tf.train.Example.FromString\n",
        "    # but that did not work\n",
        "    example = tf.io.parse_example(\n",
        "        eg[tf.newaxis],\n",
        "        {\n",
        "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "            'bathy': tf.io.FixedLenFeature([], tf.string),\n",
        "            'hs': tf.io.FixedLenFeature([], tf.string),\n",
        "            'tm01': tf.io.FixedLenFeature([], tf.string),\n",
        "            'theta0x': tf.io.FixedLenFeature([], tf.string),\n",
        "            'theta0y': tf.io.FixedLenFeature([], tf.string),\n",
        "            'eta': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'zeta': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'theta_wavex': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'theta_wavey': tf.io.FixedLenFeature([], tf.float32),\n",
        "            'mask': tf.io.FixedLenFeature([], tf.string),\n",
        "        },\n",
        "    )\n",
        "    bathy = tf.io.parse_tensor(example[\"bathy\"][0], out_type=\"float32\")\n",
        "    bathy = tf.ensure_shape(bathy, raster_shape)    # ensure shape, to be able to train the model\n",
        "    hs = tf.io.parse_tensor(example[\"hs\"][0], out_type=\"float32\")\n",
        "    hs = tf.ensure_shape(hs, raster_shape)\n",
        "    tm01 = tf.io.parse_tensor(example[\"tm01\"][0], out_type=\"float32\")\n",
        "    theta0x = tf.io.parse_tensor(example[\"theta0x\"][0], out_type=\"float32\")\n",
        "    theta0y = tf.io.parse_tensor(example[\"theta0y\"][0], out_type=\"float32\")\n",
        "    eta = example[\"eta\"]\n",
        "    zeta = example[\"zeta\"]\n",
        "    theta_wavex = example[\"theta_wavex\"]\n",
        "    theta_wavey = example[\"theta_wavey\"]\n",
        "    mask = tf.io.parse_tensor(example[\"mask\"][0], out_type=\"bool\")\n",
        "    #mask = tf.cast(mask, dtype=\"float32\")\n",
        "    mask = tf.ensure_shape(mask, raster_shape)\n",
        "    #img_input = tf.concat([bathy,mask],-1)\n",
        "    attr = tf.stack([eta, zeta, theta_wavex, theta_wavey], axis=1)\n",
        "    attr = tf.reshape(attr,shape=[-1])\n",
        "    output = (hs, tm01, theta0x, theta0y)\n",
        "    output = hs\n",
        "    return (bathy, attr), output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f602af"
      },
      "source": [
        "def get_files(data_path):\n",
        "    files = tf.io.gfile.glob(data_path + \"/\" + \"*.tfrecords\")\n",
        "    return files\n",
        "\n",
        "def get_dataset(files):\n",
        "    \"\"\"return a tfrecord dataset with all tfrecord files\"\"\"\n",
        "    dataset =  tf.data.TFRecordDataset(files)\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9OjbHWFSu4s"
      },
      "source": [
        "def AttnBlock2D(x, g, inter_channel):\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
        "\n",
        "    f = Activation('relu')(tf.keras.layers.add([theta_x, phi_g]))\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    att_x = tf.keras.layers.multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer):\n",
        "    \n",
        "    in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    up = UpSampling2D(size=(2, 2))(down_layer)\n",
        "    layer = AttnBlock2D(x=layer, g=up, inter_channel=in_channel // 4)\n",
        "    \n",
        "    my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "    \n",
        "    concate = my_concat([up, layer])\n",
        "    return concate"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47f5c590"
      },
      "source": [
        "def full_model(cnn_input_shape, mlp_input_shape):#, mask_input_shape):\n",
        "    \n",
        "    mlp_input = Input(mlp_input_shape)\n",
        "    cnn_input = Input(cnn_input_shape)\n",
        "    #mask_input = Input(mask_input_shape)\n",
        "    x = Dense(256, activation='relu')(mlp_input)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    mlp_output = Dense(4, activation='relu')(x)\n",
        "\n",
        "    x = Conv2D(16, (3,3), padding=\"same\")(cnn_input)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = MaxPooling2D(pool_size=(2,2))(x1)\n",
        "\n",
        "    x = Conv2D(32, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x1)\n",
        "\n",
        "    x = Conv2D(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = MaxPooling2D(pool_size=(2,2))(x3)\n",
        "\n",
        "    x = Conv2D(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x2 = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2))(x2)\n",
        "    \n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    cnn_output = BatchNormalization()(x)\n",
        "\n",
        "    conv_shape = K.int_shape(cnn_output)\n",
        "\n",
        "    #x = Flatten()(cnn_output)\n",
        "    #x = Dense(32, activation=\"relu\")(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Dense(32, activation=\"relu\")(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Dense(32, activation=\"relu\")(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "\n",
        "    #x = Concatenate()([x,mlp_output])\n",
        "    x = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation=\"relu\")(mlp_output)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Reshape((conv_shape[1],conv_shape[2],int(conv_shape[3])))(x)\n",
        "\n",
        "    #Concatenate cnn_output before compression with MLP output\n",
        "    x = tf.keras.layers.add([x, cnn_output])\n",
        "\n",
        "    x = Conv2D(256, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    #x = attention_up_and_concate(x, x4)\n",
        "    x = Conv2DTranspose(128, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    #x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(64, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = attention_up_and_concate(x, x2)\n",
        "    x = Conv2DTranspose(32, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    #x = attention_up_and_concate(x, x2)\n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "        \n",
        "    x = attention_up_and_concate(x, x1)\n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2DTranspose(16, (3,3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2DTranspose(1, (3,3), padding=\"same\", activation=\"linear\")(x)\n",
        "\n",
        "    model = Model(inputs=[cnn_input, mlp_input], outputs = x)\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c585d94"
      },
      "source": [
        "train_files = get_files(data_path_train)\n",
        "test_files = get_files(data_path_test)\n",
        "\n",
        "train_dataset = get_dataset(train_files)\n",
        "test_dataset = get_dataset(test_files)\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5701e49"
      },
      "source": [
        "#for sample in train_dataset.take(1):\n",
        " #   print(repr(sample))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6a01a94a",
        "outputId": "08c3e16e-b8ec-4657-9adf-94fb4e64f8c2"
      },
      "source": [
        "start = time.time()\n",
        "print(time.ctime(start))\n",
        "with tpu_strategy.scope():\n",
        "    model = full_model((256, 256, 1), 4)\n",
        "    opt = Adam(learning_rate=learning_rate, decay=learning_rate / n_epochs)\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=opt, steps_per_execution=steps_per_execution)\n",
        "    \n",
        "    callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoints_path, \n",
        "        save_weights_only=True,\n",
        "        #monitor='val_mse',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    tf.keras.callbacks.CSVLogger(\n",
        "        filename=checkpoints_path + '.csv')\n",
        "    ]\n",
        "    \n",
        "    model.fit(x=train_dataset, validation_data=test_dataset, epochs=n_epochs)#, callbacks=callbacks)#, steps_per_epoch=steps_per_epoch)\n",
        "    #model.save(model_path + '/' + model_name + '.h5')\n",
        "\n",
        "end = time.time()\n",
        "print(time.ctime(end))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 17 08:27:06 2021\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 526s 4s/step - loss: 41.8165 - val_loss: 31.1681\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 61s 540ms/step - loss: 12.8820 - val_loss: 14.4121\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 60s 535ms/step - loss: 4.5095 - val_loss: 10.4443\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 60s 535ms/step - loss: 4.1423 - val_loss: 7.1748\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 58s 517ms/step - loss: 3.8534 - val_loss: 4.2802\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 60s 536ms/step - loss: 3.7317 - val_loss: 2.4559\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 61s 540ms/step - loss: 3.5902 - val_loss: 1.8623\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 59s 524ms/step - loss: 3.4653 - val_loss: 1.9583\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 54s 481ms/step - loss: 3.3803 - val_loss: 2.0470\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 54s 477ms/step - loss: 3.2953 - val_loss: 1.9513\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 57s 511ms/step - loss: 3.2268 - val_loss: 2.0433\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 59s 525ms/step - loss: 3.1725 - val_loss: 1.7520\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 58s 519ms/step - loss: 3.1314 - val_loss: 2.0226\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 60s 537ms/step - loss: 3.1048 - val_loss: 1.8975\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 59s 524ms/step - loss: 3.0892 - val_loss: 2.0457\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 59s 526ms/step - loss: 3.1421 - val_loss: 1.7477\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 60s 533ms/step - loss: 3.0680 - val_loss: 1.7215\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 57s 506ms/step - loss: 3.0316 - val_loss: 1.7643\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 60s 534ms/step - loss: 3.0049 - val_loss: 1.7523\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 61s 540ms/step - loss: 2.9983 - val_loss: 1.8062\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 60s 534ms/step - loss: 2.9261 - val_loss: 1.7499\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 60s 531ms/step - loss: 2.8962 - val_loss: 1.6936\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 56s 498ms/step - loss: 2.8687 - val_loss: 1.6504\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 58s 512ms/step - loss: 2.8505 - val_loss: 1.7283\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 59s 522ms/step - loss: 2.8589 - val_loss: 1.7655\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 59s 526ms/step - loss: 2.8506 - val_loss: 1.7237\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 56s 496ms/step - loss: 2.8619 - val_loss: 1.8555\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 53s 469ms/step - loss: 2.9609 - val_loss: 1.6961\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 53s 472ms/step - loss: 2.9087 - val_loss: 1.7234\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 53s 472ms/step - loss: 2.8912 - val_loss: 2.0275\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 59s 522ms/step - loss: 2.8244 - val_loss: 1.9888\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 61s 543ms/step - loss: 2.7812 - val_loss: 1.9662\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 59s 529ms/step - loss: 2.7722 - val_loss: 2.3759\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 60s 537ms/step - loss: 2.8043 - val_loss: 1.9928\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 58s 515ms/step - loss: 2.7256 - val_loss: 2.1480\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 53s 471ms/step - loss: 2.7120 - val_loss: 2.3755\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 56s 494ms/step - loss: 2.7130 - val_loss: 2.4237\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 57s 508ms/step - loss: 2.7313 - val_loss: 2.1167\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 60s 538ms/step - loss: 2.7280 - val_loss: 2.2116\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 55s 490ms/step - loss: 2.7206 - val_loss: 2.3415\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 55s 488ms/step - loss: 2.7147 - val_loss: 2.4124\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 52s 461ms/step - loss: 2.7434 - val_loss: 2.5260\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 52s 467ms/step - loss: 2.8517 - val_loss: 2.1805\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 55s 489ms/step - loss: 2.8604 - val_loss: 1.7869\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 56s 499ms/step - loss: 2.7916 - val_loss: 1.7996\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 56s 495ms/step - loss: 2.7421 - val_loss: 1.9700\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 57s 504ms/step - loss: 2.7218 - val_loss: 1.8661\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 54s 481ms/step - loss: 2.7050 - val_loss: 1.8716\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 56s 494ms/step - loss: 2.6800 - val_loss: 1.7008\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 2.6312 - val_loss: 1.9018\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 49s 436ms/step - loss: 2.5922 - val_loss: 1.9886\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 54s 477ms/step - loss: 2.5495 - val_loss: 2.1703\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 55s 487ms/step - loss: 2.4868 - val_loss: 2.2543\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 53s 471ms/step - loss: 2.4037 - val_loss: 2.2933\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 2.3606"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3198b1a25c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callbacks=callbacks)#, steps_per_epoch=steps_per_epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m#model.save(model_path + '/' + model_name + '.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m       raise NotImplementedError(\"DistributedVariable.numpy() is only available \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d45a71b",
        "outputId": "78da2a4f-5fc7-474e-caba-6d57ac820d32"
      },
      "source": [
        "print(start, end)\n",
        "print(\"Starting time: \", time.ctime(start))\n",
        "print(\"Ending time: \", time.ctime(end))\n",
        "print(\"Time elapsed: \", datetime.timedelta(seconds=round(end - start)))\n",
        "print('')\n",
        "print(\"Number of parameters: \", model.count_params())\n",
        "print(\"\")\n",
        "model.save(model_path + '/' + model_name + '.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1636980355.6898663 1636986434.680863\n",
            "Starting time:  Mon Nov 15 12:45:55 2021\n",
            "Ending time:  Mon Nov 15 14:27:14 2021\n",
            "Time elapsed:  1:41:19\n",
            "\n",
            "Number of parameters:  83026599\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "816f856c"
      },
      "source": [
        "logging.info(\"training model...\")\n",
        "# TODO properly compute steps for progress bar (low priority)\n",
        "steps_per_epoch = len(train_files) * 10 // batch_size\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoints_path, \n",
        "        save_weights_only=True,\n",
        "        monitor='val_mse',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "model.fit(x=train_dataset, validation_data=test_dataset, epochs=n_epochs, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83c5e4dc",
        "outputId": "97f2f447-606f-4942-ee3e-32da628d6db6"
      },
      "source": [
        "model.summary()\n",
        "model.count_params()\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 16) 160         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 16) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 16) 64          activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 65536)        0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           4194368     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          1280        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64)           256         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 16)           1040        batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16)           64          dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4)            68          batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           528         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4)            16          dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            68          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           batch_normalization_8[0][0]      \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 65536)        589824      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 65536)        262144      dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 256)  0           reshape[0][0]                    \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 256)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 16, 16, 256)  590080      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  590080      up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  295040      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 73792       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 32) 18464       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 128, 128, 32) 0           conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 128, 128, 16) 4624        batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 128, 128, 16) 0           conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 16) 64          activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 16) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 256, 256, 1)  145         up_sampling2d_3[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 8,244,633\n",
            "Trainable params: 8,109,873\n",
            "Non-trainable params: 134,760\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8244633"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0e59b97",
        "outputId": "354fc59a-d531-40de-e83b-409ea2d2307b"
      },
      "source": [
        "pd.read_hdf(meta_data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>$\\zeta$</th>\n",
              "      <th>$\\theta_{wave}$</th>\n",
              "      <th>$\\eta$</th>\n",
              "      <th>$bathy_i$</th>\n",
              "      <th>bathy_file</th>\n",
              "      <th>bathy</th>\n",
              "      <th>uuid</th>\n",
              "      <th>run_id</th>\n",
              "      <th>bathy_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>88c98d1f-6307-43b5-a8bd-0cc6b23e105e</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>462</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-13.052446, -12.792448, -12.792448, -12.5124...</td>\n",
              "      <td>b38a89ab-f021-42dc-808e-e116dd924a46</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>318908b3-1ed1-4117-8226-6eaeb2846a24</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>462</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-13.052446, -12.792448, -12.792448, -12.5124...</td>\n",
              "      <td>dee4ae77-a3af-4e73-9f16-54b7ac589158</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.283185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.2872086, -1.2872086, -1.2872086, -1.48720...</td>\n",
              "      <td>e7bb6f7b-69db-4515-9dcf-6dc009d4d775</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>13.282544</td>\n",
              "      <td>3.631269</td>\n",
              "      <td>8.666409</td>\n",
              "      <td>100</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-21.735966, -21.735966, -21.635967, -21.6359...</td>\n",
              "      <td>65382ebd-1b80-4d75-9287-8bb7f2a41db0</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>13.581516</td>\n",
              "      <td>2.358778</td>\n",
              "      <td>29.419263</td>\n",
              "      <td>402</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[6.6918297, 6.6918297, 6.6918297, 6.6918297, ...</td>\n",
              "      <td>0402bcb5-7309-4662-8a18-93f1dccde9b4</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>8.416452</td>\n",
              "      <td>5.184157</td>\n",
              "      <td>14.352605</td>\n",
              "      <td>151</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[-1.3258033, -1.3258033, -1.3258033, -1.32580...</td>\n",
              "      <td>065553d1-f60d-4d7e-997e-0b07747682be</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>1.511433</td>\n",
              "      <td>5.741217</td>\n",
              "      <td>39.150158</td>\n",
              "      <td>367</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[20.617117, 20.617117, 20.017117, 20.017117, ...</td>\n",
              "      <td>06577167-1089-49f4-aea7-2f736f9398ca</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>11.297443</td>\n",
              "      <td>6.277600</td>\n",
              "      <td>5.148588</td>\n",
              "      <td>452</td>\n",
              "      <td>/p/11207539-001-undeepwaves/emodnet/bathymetry...</td>\n",
              "      <td>[[18.348408, 18.348408, 17.188408, 15.788408, ...</td>\n",
              "      <td>69686c04-6342-4e3b-9807-80390d75e21e</td>\n",
              "      <td>a</td>\n",
              "      <td>emodnet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1016 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        $\\zeta$  $\\theta_{wave}$     $\\eta$  $bathy_i$  \\\n",
              "0      1.000000         0.000000   1.000000          0   \n",
              "1      1.000000         0.000000   1.000000        462   \n",
              "2      1.000000         0.000000  50.000000          0   \n",
              "3      1.000000         0.000000  50.000000        462   \n",
              "4      1.000000         6.283185   1.000000          0   \n",
              "...         ...              ...        ...        ...   \n",
              "1011  13.282544         3.631269   8.666409        100   \n",
              "1012  13.581516         2.358778  29.419263        402   \n",
              "1013   8.416452         5.184157  14.352605        151   \n",
              "1014   1.511433         5.741217  39.150158        367   \n",
              "1015  11.297443         6.277600   5.148588        452   \n",
              "\n",
              "                                             bathy_file  \\\n",
              "0     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "2     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "3     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "4     /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "...                                                 ...   \n",
              "1011  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1012  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1013  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1014  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "1015  /p/11207539-001-undeepwaves/emodnet/bathymetry...   \n",
              "\n",
              "                                                  bathy  \\\n",
              "0     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "1     [[-13.052446, -12.792448, -12.792448, -12.5124...   \n",
              "2     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "3     [[-13.052446, -12.792448, -12.792448, -12.5124...   \n",
              "4     [[-1.2872086, -1.2872086, -1.2872086, -1.48720...   \n",
              "...                                                 ...   \n",
              "1011  [[-21.735966, -21.735966, -21.635967, -21.6359...   \n",
              "1012  [[6.6918297, 6.6918297, 6.6918297, 6.6918297, ...   \n",
              "1013  [[-1.3258033, -1.3258033, -1.3258033, -1.32580...   \n",
              "1014  [[20.617117, 20.617117, 20.017117, 20.017117, ...   \n",
              "1015  [[18.348408, 18.348408, 17.188408, 15.788408, ...   \n",
              "\n",
              "                                      uuid run_id bathy_source  \n",
              "0     88c98d1f-6307-43b5-a8bd-0cc6b23e105e      a      emodnet  \n",
              "1     b38a89ab-f021-42dc-808e-e116dd924a46      a      emodnet  \n",
              "2     318908b3-1ed1-4117-8226-6eaeb2846a24      a      emodnet  \n",
              "3     dee4ae77-a3af-4e73-9f16-54b7ac589158      a      emodnet  \n",
              "4     e7bb6f7b-69db-4515-9dcf-6dc009d4d775      a      emodnet  \n",
              "...                                    ...    ...          ...  \n",
              "1011  65382ebd-1b80-4d75-9287-8bb7f2a41db0      a      emodnet  \n",
              "1012  0402bcb5-7309-4662-8a18-93f1dccde9b4      a      emodnet  \n",
              "1013  065553d1-f60d-4d7e-997e-0b07747682be      a      emodnet  \n",
              "1014  06577167-1089-49f4-aea7-2f736f9398ca      a      emodnet  \n",
              "1015  69686c04-6342-4e3b-9807-80390d75e21e      a      emodnet  \n",
              "\n",
              "[1016 rows x 9 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}